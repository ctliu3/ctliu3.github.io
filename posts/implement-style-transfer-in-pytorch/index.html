<!doctype html><html><head><title>Implement style transfer in Pytorch</title><meta charset=utf-8><meta name=X-UA-Compatible content="IE=edge"><meta name=google-site-verification content><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name=viewport><meta content="telephone=no" name=format-detection><meta name=description content><meta name=renderer content="webkit"><meta name=theme-color content="#ffffff"><link type=text/css rel=stylesheet href=/vendor/css/bootstrap.min.css><link rel=stylesheet href=https://ctliu3.xyz/scss/journal.min.f4a8de07567a2d29619e0711662ef6251e3e59b642079f99490f654abf89a3c4.css integrity="sha256-9KjeB1Z6LSlhngcRZi72JR4+WbZCB5+ZSQ9lSr+Jo8Q=" media=screen><link rel=stylesheet href=https://ctliu3.xyz/scss/dark-mode.min.eeb8040aa9333250b7fec770f950bfe8ba9b18a5eeeaf2dfef61d84d3956f625.css integrity="sha256-7rgECqkzMlC3/sdw+VC/6LqbGKXu6vLf72HYTTlW9iU=" media=screen><script src=/vendor/js/loadCSS.js></script>
<script>loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons")</script><script src=/js/toc.js></script>
<script src=https://cdn.jsdelivr.net/npm/vue-disqus@3/dist/vue-disqus.js></script></head><body><div id=app><div id=sideContainer class=side-container><a class="a-block nav-head false" href=https://ctliu3.xyz/><div class=nav-title>自由の灵魂</div><div class=nav-subtitle>ctliu3's space</div></a><div class=nav-link-list><a class="a-block nav-link-item active" href=/posts>归档</a>
<a class="a-block nav-link-item false" href=/categories>分类</a></div><div class=nav-footer>Hugo Theme <a href=https://github.com/amazingrise/hugo-theme-diary>Diary</a> by <a href=https://risehere.net/>Rise</a><br>移植自 <a href=https://mak1t0.cc/ target=_blank rel="noreferrer noopener">Makito</a>'s <a href=https://github.com/SumiMakito/hexo-theme-journal/ target=_blank rel="noreferrer noopener">Journal.</a><br><br>&copy;
2022 自由の灵魂</div></div><div id=extraContainer class=extra-container><div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }"><div class=toc-content><center>- 目录 -</center><ul><ul><ul><li><a href=#style-transfer onclick="onNavClick(`#style-transfer-nav`)" id=style-transfer-nav>Style Transfer</a></li><li><a href=#make-it-faster onclick="onNavClick(`#make-it-faster-nav`)" id=make-it-faster-nav>Make it faster</a></li><li><a href=#experience-with-pytorch onclick="onNavClick(`#experience-with-pytorch-nav`)" id=experience-with-pytorch-nav>Experience with Pytorch</a></li><li><a href=#reference onclick="onNavClick(`#reference-nav`)" id=reference-nav>Reference</a></li></ul></div></div><div class=pagination><a id=globalBackToTop class="pagination-action animated-visibility" href=#top :class="{ invisible: scrollY == 0 }"><i class="material-icons pagination-action-icon">keyboard_arrow_up</i></a>
<a type=button class=pagination-action id=darkModeToggleButton><span class="material-icons pagination-action-icon" id=darkModeToggleIcon>dark_mode</span></a></div></div><div class=single-column-drawer-container id=drawer v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }"><div class=drawer-content><div class=drawer-menu><a class="a-block drawer-menu-item active" href=/posts>归档</a>
<a class="a-block drawer-menu-item false" href=/categories>分类</a></div></div></div><transition name=fade><div id=drawer-mask v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if=isDrawerOpen v-on:click=toggleDrawer></div></transition><nav id=navBar class="navbar sticky-top navbar-light single-column-nav-container"><div id=navBackground class=nav-background></div><div class="container container-narrow nav-content"><button id=nav_dropdown_btn class=nav-dropdown-toggle type=button v-on:click=toggleDrawer>
<i class=material-icons>menu</i></button>
<a id=navTitle class=navbar-brand href=https://ctliu3.xyz/>自由の灵魂</a>
<button type=button class=nav-darkmode-toggle id=darkModeToggleButton2>
<i class=material-icons id=darkModeToggleIcon2>dark_mode</i></button></div></nav><div class=single-column-header-container id=pageHead v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"><a href=https://ctliu3.xyz/><div class=single-column-header-title>自由の灵魂</div><div class=single-column-header-subtitle>ctliu3's space</div></a></div><div id=content><div id=streamContainer class=stream-container><div class="post-list-container post-list-container-shadow"><div class=post><div class=post-head-wrapper-text-only><div class=post-title>Implement style transfer in Pytorch<div class=post-meta><time itemprop=datePublished>2017-04-16 09:19</time>
<i class=material-icons>folder</i>
<a href=/categories/engineering>Engineering</a>
&nbsp;
<i class=material-icons>label</i>
<a href=/tags/pytorch>Pytorch</a>
&nbsp;
<a href=/tags/deep-learning>Deep Learning</a>
&nbsp;
<a href=/tags/computer-vision>Computer Vision</a>
&nbsp;</div></div></div><div class=post-body-wrapper><div class=post-body v-pre><p>Prisma 在去年异常火爆，它能将艺术图片（如梵高的「星空」）与任意图片融合，生成一张同时带有两者风格的图片。专业点的说法，这叫 Style transfer（风格迁移）。其实第一篇风格化相关的文章 2015 年就有了，但由于它把训练和预测放一起了，导致无法做到实时。当然，这个问题后面几个月就被解决了，也就有了再后来的 Prisma。在这篇文章里，只介绍 style transfer 的主要思路，Pytorch 实现的代码可以查看<a href=https://github.com/ctliu3/neural-style>这里</a>。</p><h3 id=style-transfer>Style Transfer</h3><p>对于一个图像分类网络，输入是图像，输出是该图像属于每个类别的概率。而训练风格迁移，输入是艺术图和待风格化的图，输出是两者的融合，即风格化后的图。虽然我拿它跟图像分类作对比，但除了都使用 CNN 来提取特征，它们并不具有可比性。具体流程可以看下面的流程图</p><figure><img src=/Implement-style-transfer-in-Pytorch/neural-style-flow.jpg alt=风格迁移流程图><figcaption><p>风格迁移流程图</p></figcaption></figure><ul><li>风络迁移网络[1]使用中间层的 feature map 来计算 loss。如果想让保留更多原图的信息，靠近输入的层可以设置较高的权重。论文中使用的是 <code>vgg19</code>，全连接层不需要用到。</li><li>使用的网络是在 imagenet 等数据集上预训练好的，网络的参数在风格化训练过程中并不更新，而是更新上图中的输入 <code>X</code>. <code>X</code> 是一幅初始图片，每一次反向传播都会更改 <code>X</code> 的像素值。为了让训练更快、更好地逼进解，可以使用待风格化的图片作为初始图片。这种利用 image graident 来更新原图的方式也可以用来生成 <a href=http://karpathy.github.io/2015/03/30/breaking-convnets/>fool image</a>。</li><li>Loss 的计算上，<code>X</code> 与艺术图和原图的 loss 上有些区别。我没实验过，但只与原图的高层特征求 loss，应该是为了让结果更接近艺术图。加上如果使用原始图片作为初始 <code>X</code> 的话，只对高层特征求 loss 确实是合理的。</li></ul><h3 id=make-it-faster>Make it faster</h3><p>每个图像都要经过多轮迭代才能得到风格化的图片，这种方法显然实用性不强。为了解决这个问题，[2] 修改了原来的训练流程：使用两个网络，一个网络用来学习风格化的参数，我们把它称为 <code>image transform net</code>，一个网络用来计算 loss，我们称之为 <code>loss net</code>。<code>loss net</code> 主要用来计算损失，因此不更新参数。<code>image transform net</code> 的输出即是最后风格化后的图。[2] 使用了如下的网络结构</p><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#069;font-weight:700>class</span> <span style=color:#0a8;font-weight:700>ImageTransformNet</span>(nn<span style=color:#555>.</span>Module):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> F<span style=color:#555>.</span>relu(self<span style=color:#555>.</span>bn1(self<span style=color:#555>.</span>conv1(x)))
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> F<span style=color:#555>.</span>relu(self<span style=color:#555>.</span>bn2(self<span style=color:#555>.</span>conv2(x)))
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> F<span style=color:#555>.</span>relu(self<span style=color:#555>.</span>bn3(self<span style=color:#555>.</span>conv3(x)))
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> self<span style=color:#555>.</span>res1(x) <span style=color:#09f;font-style:italic># residual block</span>
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> self<span style=color:#555>.</span>res2(x)
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> self<span style=color:#555>.</span>res3(x)
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> self<span style=color:#555>.</span>res4(x)
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> self<span style=color:#555>.</span>res5(x)
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> F<span style=color:#555>.</span>relu(self<span style=color:#555>.</span>bn4(self<span style=color:#555>.</span>conv4(x)))
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> F<span style=color:#555>.</span>relu(self<span style=color:#555>.</span>bn5(self<span style=color:#555>.</span>conv5(x)))
</span></span><span style=display:flex><span>        x <span style=color:#555>=</span> self<span style=color:#555>.</span>conv6(x)
</span></span><span style=display:flex><span>        <span style=color:#069;font-weight:700>return</span> x
</span></span></code></pre></div><h3 id=experience-with-pytorch>Experience with Pytorch</h3><p>其实写这个项目的主要一个原因是为了熟悉 Pytorch。这很大程度源于看了 Andrej Karpathy 的一句<a href=https://twitter.com/PyTorch/status/829539819709624321/photo/1>推文</a>。
为了吸引更多的人使用，不管是 pytorch 还是 Caffe, MXNet 等框架都在极力降低入坑的门槛，更简洁的 API，更丰富的预训练好的模型。以致发展到现在，各家的接口，在某种程度上说，长得都差不多，特别是 python 的接口。因此到最后，还是回归到架构的设计上，哪个更为灵活，使用的显存更少，更好的支持分布式训练等等。从这段时间的使用情况来看，pytorch</p><ul><li>社区并不活跃，<a href=https://discuss.pytorch.org/>discuss</a> 上的帖子并不多，回复得比较积极的似乎总是那几个人。</li><li>接口非常易用，文档相比于 Caffe, MXNet 也算完善，但离 Tensorflow 还有些距离。不过一般的问题跟跟源码或是在论坛上基本都能找到解答。</li><li>官方主打的动态图模型。我没在其它框架上写过定制化特别强的复杂网络，因此不好比较。在使用 pytorch 过程中，我确实感觉到了一些便利：定义新的 layer/loss，在 forward 过程中随意的把中间结果拿出来，放在其他网络中。</li></ul><h3 id=reference>Reference</h3><p><a href=http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf>[1]</a>: Gatys L A, Ecker A S, Bethge M, Image Style Transfer Using Convolutional Neural Networks, CVPR 2016</p><p><a href=https://arxiv.org/abs/1603.08155>[2]</a>: Johnson J, Alahi A, Fei-Fei L., Perceptual Losses for Real-Time Style Transfer and Super-Resolution, ECCV 2016</p><hr width=100% id=EOF><p style=color:#777>最后修改于 2017-04-16</p></div></div><nav class=post-pagination><a class=newer-posts>下回<br>已经到头啦。</a>
<a class=older-posts href=https://ctliu3.xyz/posts/rate-limiter/>上回<br>Rate Limiter</a></nav><div class=post-comment-wrapper><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://ctliu3.xyz/posts/implement-style-transfer-in-pytorch/",this.page.identifier="https://ctliu3.xyz/posts/implement-style-transfer-in-pytorch/"};(function(){var e=document,t=e.createElement("script");t.src="https://ctliu3.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript rel=nofollow>comments powered by Disqus.</a></noscript></div></div></div></div></div><div id=single-column-footer>Hugo Theme <a href=https://github.com/amazingrise/hugo-theme-diary>Diary</a> by <a href=https://risehere.net/>Rise</a><br>移植自 <a href=https://mak1t0.cc/ target=_blank rel="noreferrer noopener">Makito</a>'s <a href=https://github.com/SumiMakito/hexo-theme-journal/ target=_blank rel="noreferrer noopener">Journal.</a><br><br>&copy;
2022 自由の灵魂</div></div><script src=/js/journal.js></script></body></html>